# 페이징 - N번 페이지 M개 게시글

- 페이징을 처리하려면?
	- 서버 애플리케이션 내의 메모리로 디스크에 저장된 모든 데이터를 가져오고, 특정 페이지만 추출하는 것은 비효율적
		- 디스크 접근은 메모리 접근보다 느리다.
			- 디스크 I/O 비용
		- 디스크에 저장된 데이터는 메모리 용량을 초과할 수 있다.
			- Out of Memory(OOM)
				- 시스템에서 사용 가능한 메모리가 모두 사용되어 더 이상 할당할 수 없는 상황
	- 데이터베이스에서 특정 페이지의 데이터만 바로 추출하는 방법 필요
		- 페이징 쿼리

2가지 방식
- 페이지 번호
- 무한스크롤

## 페이지 번호

### 준비

- 2가지 정보 필요
	- N번 페이지에서 M개의 게시글
	- 게시글의 개수
		- 페이지당 30개의 게시글을 보여주고, 총 94개의 게시글이 있다면
		- 사용자는 클라이언트 화면에서 4번 페이지 까지 이동할 수 있다는 사실을 인지해야 함.
		- 페이지 번호 활성화에 필요

### 방법

- N번 페이지에서 M개의 게시글을 조회하려면?
	- SQL offset, limit을 활용해 페이지 쿼리를 할 수 있을 것
	- offset 지점부터 limit개의 데이터 조회
- 게시판별 게시글 목록 최신순 조회
	- shard key = board_id 이기 때문에, 단일 샤드에서 조회할 수 있다.
	- limit = M개의 게시글
	- offset = (N번 페이지 - 1) \* M
		- N > 0

```sql
select * from article #게시글 테이블
	where board_id = {board_id} #게시판 별
	order by created_at desc #최신순
	limit {limit} offset {offset}; # N번 페이지에서 M개
```

```sql
select *  
from article  
where board_id = 1  
order by created_at desc  
limit 30 offset 90;
```

<img width="216" alt="Image" src="https://github.com/user-attachments/assets/46c900fc-cf3c-4ff9-87fc-2d952bc006ee" />

3.2초가 걸렸다. 1200만건의 데이터에서 30개의 게시글을 가져오는데 3.2초. 정상적으로 서비스하기엔 어려운 상황임.

```sql
explain  
select *  
from article  
where board_id = 1  
order by created_at desc  
limit 30 offset 90;
```

`explain` 을 붙이면 query plan을 볼 수 있다.

> Query Plan: DB에서 쿼리에 의해 데이터 접근이 실행되는 계획 또는 절차
> - 사용법: explain {query}

<img width="1443" alt="Image" src="https://github.com/user-attachments/assets/015a0920-f1c5-4e10-bd33-5fc4e6e82fd0" />

- `type = ALL`: 테이블 전체를 읽는다. (풀 스캔)
- `Extra = Using where; Using filesort`
	- where절로 조건에 대해 필터링.
	- 데이터가 많기 때문에 메모리에서 정렬을 수행할 수 없어, 파일(디스크)에서 데이터를 정렬하는 filesort 수행.
전체 데이터에 대해 필터링 및 정렬하기 때문에 아주 큰 비용이 든 것이다. **인덱스**를 사용해야 함.

## 인덱스

- 데이터를 빠르게 찾기 위한 방법
- 인덱스 관리를 위해 부가적인 쓰기 작업과 공간이 필요
- 다양한 데이터 특성과 쿼리를 지원하는 다양한 자료구조
	- B+ tree
	- Hash
	- LSM tree
	- R tree
	- Bitmap
- Relational Database에서는 주로 B+ tree(Balanced Tree)
- 데이터가 정렬된 상태로 저장된다.
- 검색, 삽입, 삭제 연산을 로그 시간에 수행 가능
- 트리 구조에서 leaf node 간 연결되기 때문에 범위 검색 효율적
- 인덱스를 추가하면,
	- 쓰기 시점에 B+ tree 구조의 정렬된 상태의 데이터가 생성된다.
- 이미 인덱스로 지정된 컬럼에 대해 정렬된 상태를 가지고 있기 때문에,
	- 조회 시점에 전체 데이터를 정렬하고 필터링할 필요가 없다.
	- 따라서, 조회 쿼리를 빠르게 수행할 수 있다.

```sql
create index idx_board_id_article_id on article (board_id asc, article_id desc);
```

- board_id 오름차순, article_id 내림차순 정렬
- 인덱스는 순서가 중요
	- 게시판별로 생성 시간 순으로 정렬된 상태의 데이터가 만들어질 것

### article_id에 index를 거는 이유

왜 최신순을 위한 index인데 `createdAt`에 걸지 않고 `article_id` 에 거는가?
- 대규모 트래픽을 처리하기 위한 분산환경임
- 어플리케이션은 여러 서버로 분산, **동시**에 처리될 수 있음.
- 게시글이 **동시**에 생성될 수 있는 것.
	- 테스트 데이터도 멀티스레드에서 동시에 생성되었기 때문에, 동일 시간을 가지는 데이터가 많을 것임.

<img width="1306" alt="Image" src="https://github.com/user-attachments/assets/a43619ef-d023-492c-9652-baf259eca050" />
동시 요청시 생성 시간은 충돌될 수 있으므로 `created_at` 을 정렬조건으로 사용하면 동일 생성 시간 순서가 명확하지 않음.
`article_id` 는 분산 시스템에서 고유한 오름차순을 위해 고안된 알고리즘 (Snowflake)을 사용. 충돌 확률이 완전히 0은 아니지만 생성시간보다 충돌 가능성이 작음.

```sql {4}
select *  
from article  
where board_id = 1  
order by article_id desc  
limit 30 offset 90;
```

article_id를 order 조건으로 잡음.

생성한 인덱스는 아래와 같은 모습임. board_id를 기준 오름차순, article_id기준 내림차순.
<img width="1222" alt="Image" src="https://github.com/user-attachments/assets/b95a03c9-e582-472a-bf3a-04e66fce2627" />
다시 조회하면
<img width="169" alt="Image" src="https://github.com/user-attachments/assets/2ac0e3d1-009f-4432-8b46-cac0ad8cb542" />
113ms밖에 걸리지 않음.

<img width="1417" alt="Image" src="https://github.com/user-attachments/assets/cd0e2a12-a8e8-41ce-b3dc-c8fcc49daa2b" />

플랜을 살펴보면 `key = idx_board_id_article_id` 가 걸려있다.
이번엔 5000개의 데이터를 가져와보자.

```sql
select *  
from article  
where board_id = 1  
order by article_id desc  
limit 30 offset 1499970  
```

<img width="209" alt="Image" src="https://github.com/user-attachments/assets/7819f8fb-8f2a-4b06-ad44-f2765d3f18d2" />
2s 736ms 가 걸림. explain을 걸어서 보면

<img width="208" alt="Image" src="https://github.com/user-attachments/assets/469eb200-178e-49b9-90e7-a3c524aca757" />

여전히 index를 잘 타고 있음.
인덱스의 종류를 알아야 함.

### 인덱스의 종류

1. Clustered Index
2. Secondary Index

#### Clustered Index

- MySQL의 기본 스토리지 엔진
	- InnoDB
	- 스토리지 엔진(Storage Engine): DB에서 데이터 저장 및 관리 장치
- 그리고, InnoDB는 테이블마다 Clustered Index를 자동 생성한다.
	- Primary Key를 기준으로 정렬된 Clustered Index
		- Primary Index(주 인덱스)라고도 불린다.
		- 정확히는 규칙이 있지만, 일반적으로 Primary Key에 생성된다.
	- Clustered Index는 leaf node의 값으로 행 데이터(row data)를 가진다.

<img width="1235" alt="Image" src="https://github.com/user-attachments/assets/ab965455-4856-448d-a2a8-0d1950609ae1" />
article 테이블에는 article_id를 기준으로 하는 Clustered Index가 생성되어 있고, 데이터를 가진다.
Primary Key를 이용한 조회는, 자동으로 생성된 Clustered Index로 수행되는 것이다.

<img width="1203" alt="Image" src="https://github.com/user-attachments/assets/953341b0-0674-45e6-a1da-d4fefe245799" />

`key = PRIMARY`
별도로 index를 생성한 적이 없는데도, 인덱스가 사용됨. primary key에 자동으로 생성된 Clustered Index가 사용된 것.

#### Secondary Index

- 그러면, 우리가 생성한 인덱스는 무엇일까?
	- 우리가 생성하는 인덱스는 Secondary Index(보조 인덱스)라고 부른다.
	- Non-clustered Index라고도 불린다.
- Secondary Index의 leaf node는 다음 데이터를 가지고 있다.
	- 인덱스 컬럼 데이터
	- 데이터에 접근하기 위한 포인터
		- 데이터는 Clustered Index가 가지고 있다.
			- Clustered Index의 데이터에 접근하기 위한 포인터
			- Primary Key

<img width="1351" alt="Image" src="https://github.com/user-attachments/assets/893feef0-d43e-425c-8975-60f93c620595" />

article_id는 인덱스 컬럼 데이터이면서 데이터에 접근하기 위한 포인터이다.

<img width="1211" alt="Image" src="https://github.com/user-attachments/assets/28263176-a48a-4f2a-9c57-83ed373624d6" />

- Primary Key를 이용한 데이터 조회는 Clustered Index를 통해 데이터를 빠르게 찾을 수 있었다.
- 그렇다면, Secondary Index를 이용한 조회는 어떻게 처리되는 것일까?
- Secondary Index는 데이터에 접근하기 위한 포인터만 가지고 있다.
- 그리고 데이터는 Clustered Index가 가지고 있다.
- Secondary Index를 통해 데이터가 조회되는 과정을 살펴보자.

col=4의 데이터를 조회해보자.

<img width="1358" alt="Image" src="https://github.com/user-attachments/assets/4239f8b6-481e-40ff-8d91-13d73f629a55" />
col 컬럼에 인덱스가 있기 때문에 빠르게 조회할 수 있을 것이다.
Secondary Index를 먼저 조회하여, 데이터 접근할 수 있는 포인터(id)를 찾는다.

<img width="1344" alt="Image" src="https://github.com/user-attachments/assets/9bef877c-fb6a-4bc9-a011-44822671cfa1" />
Secondary Index에서 데이터 접근을 위한 포인터 id=4를 찾았다

<img width="1276" alt="Image" src="https://github.com/user-attachments/assets/202fd204-eb51-4612-9ac7-3e6a5b7a40a6" />
id=4의 데이터 data4를 찾을 수 있다.

- Secondary Index를 이용한 데이터 조회는, 인덱스 트리를 두 번 타고 있는 것이다.
	1. Secondary Index에서 데이터에 접근하기 위한 **포인터**를 찾은 뒤,
	2. Clustered Index에서 데이터를 찾는다.

```sql
select * from article
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```

1. (board_id, article_id)에 생성된 Secondary Index에서 article_id를 찾는다.
2. Clustered Index에서 article 데이터를 찾는다.
3. offset 1499970을 만날 때까지 반복하며 skip 한다.
4. limit 30개를 추출한다.

- Secondary Index에서 필요한 30건에 대해서 article_id만 먼저 추출하고,
- 그 30건에 대해서만 Clustered Index에 접근하면 충분하지 않을까?
- article_id는 Clustered Index에 접근하지 않아도 가져올 수 있는 정보일지 모른다.
- 과연 그렇게 동작할 수 있을까?

쿼리를 board_id와 article_id만 추출하도록 바꿔서 수행해보자.

```sql {1}
select board_id, article_id
from article
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```

<img width="190" alt="Image" src="https://github.com/user-attachments/assets/27c3bf2f-174f-4786-bdf1-5e35265eff8a" />

전체 데이터를 가져올 때에는 약 4초가 소요되었는데, board_id와 article_id만 추출하는 것은 0.2초가 소요되었다.

<img width="1438" alt="Image" src="https://github.com/user-attachments/assets/11104aa0-7079-49e0-8bb9-020a44e9ac67" />

plan이다. `Using index` 라고 적힌 부분을 보자. 인덱스만 사용해서 조회한다는 뜻.
이것이 Covering Index다.

- Covering Index
	- 인덱스만으로 쿼리의 모든 데이터를 처리할 수 있는 인덱스
	- 데이터(Clustered Index)를 읽지 않고, 인덱스(Secondary Index) 포함된 정보만으로 쿼리 가능한 인덱스

이번 쿼리에서는 Clustered Index에 접근하는 과정은 없었다. Covering Index를 활용하여, Secondary Index에서만 board_id와 article_id를 추출한 것이다.

이제 추출된 30건의 article_id에 대해서만 Clustered Index에 접근하면 된다!
- 30건의 article_id를 sub query의 결과로 만들고, article 테이블과 join해보자.

```sql
select *  
from (select article_id  
      from article  
      where board_id = 1  
      order by article_id desc  
      limit 30 offset 1499970) t  
         left join article on t.article_id = article.article_id;
```

<img width="195" alt="Image" src="https://github.com/user-attachments/assets/c7300981-4f76-4ade-a12a-0ba38f08e771" />

<img width="1161" alt="Image" src="https://github.com/user-attachments/assets/a6dc4e1b-d004-4eeb-a4e1-3f615150e98e" />

Covering Index를 활용하여, offset 1499970에서부터 Clustered Index에 접근하게 된 것이다. 무의미한 데이터 접근 과정이 사라졌다.

Query Plan도 살펴보자. article_id 추출을 위한 sub query 과정에 파생 테이블 생기지만(DERIVED), 이 과정에서 커버링 인덱스가 사용되었다. 작은 규모의 파생 테이블과 join하여 30건에 대해서만 Clustered Index(PRIMARY)에서 데이터를 가져오기 때문에 빠르게 처리될 수 있었다.

300,000번 페이지를 조회 해보자.

```sql
select *  
from (select article_id  
      from article  
      where board_id = 1  
      order by article_id desc  
      limit 30 offset 8999970) t  
         left join article on t.article_id = article.article_id;
```

<img width="210" alt="Image" src="https://github.com/user-attachments/assets/126b9c7e-5801-4859-aaea-5fb5de93b306" />
이번에는 약 1.5초가 소요되었다. Query Plan도 동일하다. 뒷 페이지로 갈수록 속도가 느려지는 문제는 여전한 것이다. 왜 그럴까?

동작 과정을 생각해보면 당연하다. article_id 추출을 위해 Secondary Index만 탄다고 하더라도, offset 만큼 Index Scan이 필요하다.
데이터에 접근하지 않더라도 offset이 늘어날 수록 느려질 수 밖에 없는 것이다.

#### 해결

- 데이터를 한 번 더 분리한다.
- 예를 들면, 게시글을 1년 단위로 테이블 분리
	- 개별 테이블의 크기를 작게 만든다.
	- 각 단위에 대해 전체 게시글 수를 관리한다.
- offset을 인덱스 페이지 단위 skip하는 것이 아니라, 1년 동안 작성된 게시글 수 단위로 즉시 skip한다.
	- 조회하고자 하는 offset이 1년 동안 작성된 게시글 수보다 크다면,
		- 해당 개수 만큼 즉시 skip
		- 더 큰 단위로 skip을 수행하게 되는 것
	- 애플리케이션에서 이처럼 처리하기 위한 코드 작성 필요
- 300,000번 페이지를 조회하는게 정상적인 사용자일까?
	- 데이터 수집을 목적으로 하는 어뷰저일 수도 있다.
	- 정책으로 풀어내기
		- 예를 들면, 게시글 목록 조회는 10,000번 페이지까지 제한한다.
	- 시간 범위 또는 텍스트 검색 기능을 제공할 수도 있다.
		- 더 작은 데이터 집합 내에서 페이징을 수행한다.
